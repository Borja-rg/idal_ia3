{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smoke classification (Attempts).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Borja-rg/idal_ia3/blob/main/Smoke_classification_(Attempts).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTwIOYLHxuhP"
      },
      "source": [
        "<img src = \"https://static.casadomo.com/media/2020/02/lonmark-espana-universidad-valencia-jornada-automatizacion.png\" align=\"right\" style=\"float\" width=\"300\">\r\n",
        "\r\n",
        "\r\n",
        "# **WILDFIRE SMOKE CLASSIFICATION**\r\n",
        "##**(Attempts with Full Images)**\r\n",
        "\r\n",
        "### Borja Ramón Gómez "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-kVFdy8zg9N"
      },
      "source": [
        "En este notebook se ha intentado analizar fotografías completas de bosques con humo causado por un incendio, provenientes del Wildfire Smoke Dataset. El objetivo es diseñar una CNN capaz de clasificar las imágenes en función de si tienen humo o no. A continuación constan los distintos pasos e intentos realizadas:\r\n",
        "\r\n",
        "1.   Importación y preparación de los datos de entrenamiento, validación y testeo.\r\n",
        "2.   Intento I: Diseño de una CNN propia.\r\n",
        "3.   Intento II: Transfer Learning (EfficientNet)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ-ePeWXxvo2"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import tensorflow.keras as keras\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "import numpy as np\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\n",
        "from keras.models import Sequential, load_model, Model\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\r\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\r\n",
        "from keras import backend as K\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras import regularizers\r\n",
        "from keras import optimizers\r\n",
        "from keras import models\r\n",
        "from glob import glob\r\n",
        "import cv2\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "\r\n",
        "from IPython.display import SVG, display, clear_output\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWLzvmbFFHfx",
        "outputId": "5a6d8059-5913-47fd-ac35-4d27ba99d3c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC-wwKTJ3Cxt"
      },
      "source": [
        "## **1. Importación y Preparación de Datos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq6pknfQ3Ktf"
      },
      "source": [
        "A continuación se importan las imágenes utilizadas. 1336 imágenes divididas casi equitativamente entre la clase Humo y No Humo, son repartidas entre los conjuntos de entrenamiento, validación y testeo con unos ratios de 70%, 20% y 10% respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q3BzMAJQheu"
      },
      "source": [
        "!unzip drive/MyDrive/SMOKE/challenge1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HasbX5YKXdaQ"
      },
      "source": [
        "smoke = glob('challenge1/smoke/*jpg')\r\n",
        "no_smoke = glob('challenge1/no_smoke/*jpg')\r\n",
        "random.shuffle(smoke)\r\n",
        "random.shuffle(no_smoke)\r\n",
        "train_ratio = 0.7\r\n",
        "val_ratio = 0.2\r\n",
        "\r\n",
        "num_smoke = len(smoke)\r\n",
        "num_nosmoke = len(no_smoke)\r\n",
        "\r\n",
        "train_smoke = smoke[:round(train_ratio*num_smoke)]\r\n",
        "train_nosmoke = no_smoke[:round(train_ratio*num_nosmoke)]\r\n",
        "\r\n",
        "val_smoke = smoke[round(train_ratio*num_smoke):round((train_ratio+val_ratio)*num_smoke)]\r\n",
        "val_nosmoke = no_smoke[round(train_ratio*num_nosmoke):round((train_ratio+val_ratio)*num_nosmoke)]\r\n",
        "\r\n",
        "test_smoke = smoke[round((train_ratio+val_ratio)*num_smoke):]\r\n",
        "test_nosmoke = no_smoke[round((train_ratio+val_ratio)*num_nosmoke):]\r\n",
        "\r\n",
        "train_X = train_smoke + train_nosmoke\r\n",
        "train_y = len(train_smoke) * ['Smoke'] + len(train_nosmoke)*['No smoke']\r\n",
        "\r\n",
        "val_X = val_smoke + val_nosmoke\r\n",
        "val_y = len(val_smoke) * ['Smoke'] + len(val_nosmoke)*['No smoke']\r\n",
        "\r\n",
        "test_X = test_smoke + test_nosmoke\r\n",
        "test_y = len(test_smoke) * ['Smoke'] + len(test_nosmoke)*['No smoke']\r\n",
        "\r\n",
        "df_train = pd.DataFrame(columns=['filepath','class'])\r\n",
        "df_train['filepath'] = train_X\r\n",
        "df_train['class'] = train_y\r\n",
        "\r\n",
        "df_val = pd.DataFrame(columns=['filepath','class'])\r\n",
        "df_val['filepath'] = val_X\r\n",
        "df_val['class'] = val_y\r\n",
        "\r\n",
        "df_test = pd.DataFrame(columns=['filepath','class'])\r\n",
        "df_test['filepath'] = test_X\r\n",
        "df_test['class'] = test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Qvyln3a7Fn",
        "outputId": "ac03597e-0674-45eb-9e0c-06291cb989fe"
      },
      "source": [
        "tot = len(smoke)+len(no_smoke)\r\n",
        "print(f'Number of total images: \\nSmoke = {len(smoke)} ({round(len(smoke)/tot*100,2)} %)\\nNo smoke = {len(no_smoke)} ({round(len(no_smoke)/tot*100,2)} %)')\r\n",
        "print(f'Ratios: Train 70%, Validation 20%, Test 10%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of total images: \n",
            "Smoke = 713 (53.37 %)\n",
            "No smoke = 623 (46.63 %)\n",
            "Ratios: Train 70%, Validation 20%, Test 10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUBDDl6q5clH"
      },
      "source": [
        "Con el objetivo de no cargar todas las imágenes a memoria, se crea un generador para cada set de datos que introduce progresivamente los datos en batches. Se ha decidido realizar data augmentation para el conjunto de entrenamiento, dada la reducida cantidad de datos disponibles. Merece la pena mencionar que las imágenes son de una alta resolución, 1536 x 2048."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i0aC0RKio_n"
      },
      "source": [
        "batch_size = 4\r\n",
        "\r\n",
        "train_gen = ImageDataGenerator(dtype='float32',\r\n",
        "                              preprocessing_function = lambda x:x/255,\r\n",
        "                              rotation_range=10,\r\n",
        "                              width_shift_range=0.1,\r\n",
        "                              height_shift_range=0.1,\r\n",
        "                              fill_mode='nearest',\r\n",
        "                              shear_range=0.1,\r\n",
        "                              zoom_range=0.2,\r\n",
        "                              horizontal_flip=True)\r\n",
        "\r\n",
        "val_gen  = ImageDataGenerator(dtype='float32', preprocessing_function = lambda x:x/255)\r\n",
        "\r\n",
        "test_gen = ImageDataGenerator(dtype='float32', preprocessing_function = lambda x:x/255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z82tL4S5n5E",
        "outputId": "5358421b-be9c-41a0-811f-ddb6f02d6939"
      },
      "source": [
        "sizes = {}\r\n",
        "for i in range(len(train_nosmoke)):\r\n",
        "  im = train_nosmoke[i]\r\n",
        "  image = load_img(im)\r\n",
        "#  display(image)\r\n",
        "  size = np.array(image).shape\r\n",
        "  if size not in sizes:\r\n",
        "    sizes[size] = 1\r\n",
        "  else:\r\n",
        "    sizes[size] += 1\r\n",
        "sizes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(1536, 2048, 3): 240, (2048, 3072, 3): 196}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Low6cmp7HOLZ"
      },
      "source": [
        "target_size = (1536, 2048)\r\n",
        "input_shape = (1536, 2048, 3)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "264PqOzWmI1I",
        "outputId": "e03b6a6e-7a1c-45ad-98ac-8ead8e8fe526"
      },
      "source": [
        "train_generator = train_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_train,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "val_generator = val_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_val,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "test_generator = test_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_test,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 935 validated image filenames belonging to 2 classes.\n",
            "Found 268 validated image filenames belonging to 2 classes.\n",
            "Found 133 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL_qhXjS9HRS"
      },
      "source": [
        "## 2. Diseño y Entrenamiento de CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Csebf49Q0N"
      },
      "source": [
        "En esta sección se diseña una red convolucional y se obtiene su rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2PKuHF-ZDsb"
      },
      "source": [
        "dropout = 0.5\r\n",
        "regul = 'l2'\r\n",
        "optimizer = 'adam'\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\r\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2,2)))\r\n",
        "model.add(Dropout(dropout))\r\n",
        "\r\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\r\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2,2)))\r\n",
        "model.add(Dropout(dropout))\r\n",
        "\r\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2,2)))\r\n",
        "\r\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2,2)))\r\n",
        "\r\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2,2)))\r\n",
        "\r\n",
        "model.add(GlobalAveragePooling2D())\r\n",
        "\r\n",
        "model.add(Dropout(dropout))\r\n",
        "model.add(Dense(128, activation='relu',kernel_regularizer = regul))\r\n",
        "model.add(Dropout(dropout))\r\n",
        "model.add(Dense(64, activation='relu',kernel_regularizer = regul))\r\n",
        "model.add(Dropout(dropout))\r\n",
        "model.add(Dense(16, activation='relu',kernel_regularizer = regul))\r\n",
        "model.add(Dropout(dropout))\r\n",
        "model.add(Dense(2))\r\n",
        "model.add(Activation('softmax')) \r\n",
        "model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APKBhG0EcUXB"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82SsbvHGHVrr"
      },
      "source": [
        "epochs = 5\r\n",
        "modelpath=\"best_model.h5\"\r\n",
        "callback = [ModelCheckpoint(modelpath, monitor='val_accuracy', verbose=1,\r\n",
        "                              save_best_only=True,\r\n",
        "                              mode='max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scC5EijFEf9q",
        "outputId": "1d3844df-646b-4e10-c628-ee01934fbf71"
      },
      "source": [
        "history = model.fit(train_generator,\r\n",
        "                    batch_size = batch_size,\r\n",
        "                    epochs = epochs,\r\n",
        "                    callbacks = callback,\r\n",
        "                    validation_data = val_generator\r\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "234/234 [==============================] - 855s 4s/step - loss: 1.3819 - accuracy: 0.4680 - val_loss: 0.7989 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.53358, saving model to best_model.h5\n",
            "Epoch 2/5\n",
            "234/234 [==============================] - 830s 4s/step - loss: 0.7671 - accuracy: 0.5184 - val_loss: 0.7101 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.53358\n",
            "Epoch 3/5\n",
            "234/234 [==============================] - 837s 4s/step - loss: 0.7054 - accuracy: 0.5296 - val_loss: 0.6957 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.53358\n",
            "Epoch 4/5\n",
            "234/234 [==============================] - 839s 4s/step - loss: 0.6963 - accuracy: 0.5269 - val_loss: 0.6926 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.53358\n",
            "Epoch 5/5\n",
            "234/234 [==============================] - 823s 4s/step - loss: 0.6925 - accuracy: 0.5326 - val_loss: 0.6916 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.53358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f696YsWOGUnY",
        "outputId": "8b3c9104-c35c-4740-8ad3-4731bfbac52b"
      },
      "source": [
        "scores_tr = model.evaluate(train_generator)\r\n",
        "print('Train loss    :', scores_tr[0])\r\n",
        "print('Train accuracy:', scores_tr[1])\r\n",
        "print()\r\n",
        "\r\n",
        "scores_val = model.evaluate(val_generator)\r\n",
        "print('Val loss    :', scores_val[0])\r\n",
        "print('Val accuracy:', scores_val[1])\r\n",
        "print()\r\n",
        "\r\n",
        "scores_te = model.evaluate(test_generator)\r\n",
        "print('Test loss     :', scores_te[0])\r\n",
        "print('Test accuracy :', scores_te[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 59s 2s/step - loss: 0.7129 - accuracy: 0.5337\n",
            "Train loss    : 0.7129409313201904\n",
            "Train accuracy: 0.5336898565292358\n",
            "\n",
            "9/9 [==============================] - 14s 2s/step - loss: 0.7130 - accuracy: 0.5336\n",
            "Val loss    : 0.7129531502723694\n",
            "Val accuracy: 0.5335820913314819\n",
            "\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.7129 - accuracy: 0.5338\n",
            "Test loss     : 0.7129253149032593\n",
            "Test accuracy : 0.5338345766067505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE35ZH679AIC"
      },
      "source": [
        "Este mismo procedimiento se ha intentado para distintos parámetros de dropout, tamaño del batch, regularizaciones y número de capas. Para todos los casos se ha obtenido que la red no es capaz de obtener información a partir de las fotografías, ya que la accuracy es del 0.53. \r\n",
        "\r\n",
        "Esto probablemente se deba al gran tamaño de las fotografías de entrada en comparación con el humo. Por ello, se necesitaría una red más profunda y adaptada a entradas grandes, lo cual se va a intentar con Transfer Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgiHWGajnPtW"
      },
      "source": [
        "## 3. Transfer Learning: Red EfficientNetB7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUIYA9qyCAsr"
      },
      "source": [
        "En este apartado se utiliza la red convolucional llamada EfficientNetB7, la cual ha sido escogida por haber sido entrenada para el mayor tamaño de entrada de las disponibles en keras applications, 600 x 600.\r\n",
        "\r\n",
        "Esta red se utiliza para diseñar 3 redes distintas y comprobar su eficacia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dB2PMLx4Nji"
      },
      "source": [
        "input_shape_tl = (2400,2400,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNIk0ljdXEH5"
      },
      "source": [
        "from tensorflow.keras.applications import Xception, VGG16, ResNet50, VGG19, EfficientNetB7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNSNkCkkrd1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7007f7b8-ceb2-4a9d-c174-2d6277c1e5ab"
      },
      "source": [
        "efficient = EfficientNetB7(weights='imagenet', include_top = False)\r\n",
        "efficient_2 = EfficientNetB7(weights = 'imagenet', include_top=False,input_shape = (600,600,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258080768/258076736 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdniaNMTB1U8"
      },
      "source": [
        "efficient.trainable = False\r\n",
        "efficient.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzo-liVUCuhk"
      },
      "source": [
        "La primera approximación utilizando la EfficientNet consta de modificar todas las imágenes de entrada a un tamaño de 2400 x 2400. Esto se hace para añadir dos capas convolucionales y max pooling antes del modelo para reducir las entradas a 600 x 600. Tras concatenar el modelo, se añaden unas capas densas a la salida. Finalmente se entrenan las capas nuevas, dejando el modelo Efficient con los pesos originales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGSKCL9kDVCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6051d95b-d983-4258-f10a-f0b1913d848d"
      },
      "source": [
        "my_submodel = Sequential()\r\n",
        "my_submodel.add(Conv2D(3,(3,3),padding='same',input_shape = input_shape_tl))\r\n",
        "my_submodel.add(MaxPooling2D((2,2)))\r\n",
        "my_submodel.add(Conv2D(3,(3,3),padding='same'))\r\n",
        "my_submodel.add(MaxPooling2D((2,2)))\r\n",
        "my_submodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 2400, 2400, 3)     84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 1200, 1200, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 1200, 1200, 3)     84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 600, 600, 3)       0         \n",
            "=================================================================\n",
            "Total params: 168\n",
            "Trainable params: 168\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ksKUfy-P69A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b81b08-f440-4eae-d15d-cd29f1a05e45"
      },
      "source": [
        "efficient.trainable=False\r\n",
        "x = my_submodel.output\r\n",
        "out = efficient(x)\r\n",
        "global_avg = GlobalAveragePooling2D()(out)\r\n",
        "dense_01 = keras.layers.Dense(units=256,activation=\"relu\")(global_avg)\r\n",
        "drop = keras.layers.Dropout(0.5)(dense_01)\r\n",
        "dense_02 = keras.layers.Dense(units=64,activation=\"relu\")(drop)\r\n",
        "drop2 = keras.layers.Dropout(0.5)(dense_02)\r\n",
        "dense_02 = keras.layers.Dense(2)(drop2)\r\n",
        "act = keras.layers.Activation('softmax')(dense_02)\r\n",
        "tot_model = Model(my_submodel.input, act)\r\n",
        "tot_model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "tot_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30_input (InputLayer) [(None, 2400, 2400, 3)]   0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 2400, 2400, 3)     84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 1200, 1200, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 1200, 1200, 3)     84        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 600, 600, 3)       0         \n",
            "_________________________________________________________________\n",
            "efficientnetb7 (Functional)  (None, None, None, 2560)  64097687  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_5 ( (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               655616    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 130       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 64,770,049\n",
            "Trainable params: 672,362\n",
            "Non-trainable params: 64,097,687\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoyWINxv3b-i"
      },
      "source": [
        "target_size = (2400,2400)\r\n",
        "batch_size = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hObx66S13Xzj",
        "outputId": "4eec7249-15c5-4952-839f-e63df2fd98d5"
      },
      "source": [
        "train_generator_tl = train_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_train,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "val_generator_tl = val_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_val,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "test_generator_tl = test_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_test,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 935 validated image filenames belonging to 2 classes.\n",
            "Found 268 validated image filenames belonging to 2 classes.\n",
            "Found 133 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr23W_po_AD7"
      },
      "source": [
        "for batch in test_generator_tl:\r\n",
        "  im = batch[0][31]\r\n",
        "  plt.imshow(im)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dGqcfeY7P9P",
        "outputId": "82ea7b8f-72c2-406f-f29b-ad79dab7f058"
      },
      "source": [
        "history_tl = tot_model.fit(train_generator_tl,\r\n",
        "             batch_size = batch_size,\r\n",
        "             epochs = 2,\r\n",
        "             validation_data = val_generator_tl\r\n",
        "             )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 1527s 3s/step - loss: 0.8723 - accuracy: 0.4845 - val_loss: 0.6911 - val_accuracy: 0.5336\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 1497s 3s/step - loss: 0.7151 - accuracy: 0.5316 - val_loss: 0.6911 - val_accuracy: 0.5336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UveqMppq_1c_",
        "outputId": "995830f6-7bf9-4bac-cad0-8f8106824551"
      },
      "source": [
        "scores_tr = tot_model.evaluate(train_generator_tl)\r\n",
        "print('Train loss    :', scores_tr[0])\r\n",
        "print('Train accuracy:', scores_tr[1])\r\n",
        "print()\r\n",
        "\r\n",
        "scores_val = tot_model.evaluate(val_generator_tl)\r\n",
        "print('Val loss    :', scores_val[0])\r\n",
        "print('Val accuracy:', scores_val[1])\r\n",
        "print()\r\n",
        "\r\n",
        "scores_te = tot_model.evaluate(test_generator_tl)\r\n",
        "print('Test loss     :', scores_te[0])\r\n",
        "print('Test accuracy :', scores_te[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "468/468 [==============================] - 1219s 3s/step - loss: 0.6911 - accuracy: 0.5337\n",
            "Train loss    : 0.6910744905471802\n",
            "Train accuracy: 0.5336898565292358\n",
            "\n",
            "134/134 [==============================] - 48s 357ms/step - loss: 0.6910 - accuracy: 0.5336\n",
            "Val loss    : 0.6909761428833008\n",
            "Val accuracy: 0.5335820913314819\n",
            "\n",
            "67/67 [==============================] - 24s 354ms/step - loss: 0.6912 - accuracy: 0.5338\n",
            "Test loss     : 0.6912146210670471\n",
            "Test accuracy : 0.5338345766067505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_SwA7k0Dezr"
      },
      "source": [
        "El segundo acercamiento utilizando la red EfficientNet consta de retirar las capas convolucionales iniciales y dejar que los propios generaciones reduzcan las imágenes de entrada al tamaño de entrada de la red, 600 x 600."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbhZDaVlRVoW",
        "outputId": "2320d381-0816-416a-a4a6-681c413e5e31"
      },
      "source": [
        "target_size_2 = (600,600)\r\n",
        "batch_size = 8\r\n",
        "\r\n",
        "train_generator_tl_2 = train_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_train,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size_2,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "val_generator_tl_2 = val_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_val,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size_2,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "test_generator_tl_2 = test_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_test,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size_2,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 935 validated image filenames belonging to 2 classes.\n",
            "Found 268 validated image filenames belonging to 2 classes.\n",
            "Found 133 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp3g8C8bRxw2"
      },
      "source": [
        "efficient_2.trainable=False\r\n",
        "x = efficient_2.output\r\n",
        "global_avg = GlobalAveragePooling2D()(x)\r\n",
        "dense_01 = keras.layers.Dense(units=256,activation=\"relu\")(global_avg)\r\n",
        "drop = keras.layers.Dropout(0.5)(dense_01)\r\n",
        "dense_02 = keras.layers.Dense(units=64,activation=\"relu\")(drop)\r\n",
        "drop2 = keras.layers.Dropout(0.5)(dense_02)\r\n",
        "dense_02 = keras.layers.Dense(2)(drop2)\r\n",
        "act = keras.layers.Activation('softmax')(dense_02)\r\n",
        "tot_model_2 = Model(efficient_2.input, act)\r\n",
        "tot_model_2.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "tot_model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH5o74z6TCAX",
        "outputId": "98f1be84-d60e-45f9-ccf8-40e3c598c061"
      },
      "source": [
        "history_tl_2 = tot_model_2.fit(train_generator_tl_2,\r\n",
        "             batch_size = batch_size,\r\n",
        "             epochs = 4,\r\n",
        "             validation_data = val_generator_tl_2\r\n",
        "             )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "117/117 [==============================] - 191s 1s/step - loss: 0.8578 - accuracy: 0.5196 - val_loss: 0.6910 - val_accuracy: 0.5336\n",
            "Epoch 2/4\n",
            "117/117 [==============================] - 173s 1s/step - loss: 0.7022 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5336\n",
            "Epoch 3/4\n",
            "117/117 [==============================] - 169s 1s/step - loss: 0.6937 - accuracy: 0.4957 - val_loss: 0.6918 - val_accuracy: 0.5336\n",
            "Epoch 4/4\n",
            "117/117 [==============================] - 169s 1s/step - loss: 0.6898 - accuracy: 0.5668 - val_loss: 0.6912 - val_accuracy: 0.5336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvHL2DWxZj9i",
        "outputId": "62aa6022-447a-4cb8-a458-9858330ecced"
      },
      "source": [
        "scores_tr = tot_model_2.evaluate(train_generator_tl_2)\r\n",
        "print('Train loss    :', scores_tr[0])\r\n",
        "print('Train accuracy:', scores_tr[1])\r\n",
        "print()\r\n",
        "\r\n",
        "scores_val = tot_model_2.evaluate(val_generator_tl_2)\r\n",
        "print('Val loss    :', scores_val[0])\r\n",
        "print('Val accuracy:', scores_val[1])\r\n",
        "print()\r\n",
        "\r\n",
        "scores_te = tot_model_2.evaluate(test_generator_tl_2)\r\n",
        "print('Test loss     :', scores_te[0])\r\n",
        "print('Test accuracy :', scores_te[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "117/117 [==============================] - 148s 1s/step - loss: 0.6912 - accuracy: 0.5337\n",
            "Train loss    : 0.6911768913269043\n",
            "Train accuracy: 0.5336898565292358\n",
            "\n",
            "34/34 [==============================] - 25s 723ms/step - loss: 0.6912 - accuracy: 0.5336\n",
            "Val loss    : 0.6911858916282654\n",
            "Val accuracy: 0.5335820913314819\n",
            "\n",
            "17/17 [==============================] - 14s 779ms/step - loss: 0.6912 - accuracy: 0.5338\n",
            "Test loss     : 0.6911644339561462\n",
            "Test accuracy : 0.5338345766067505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaPIBN97kegD"
      },
      "source": [
        "def get_roc(models, test_gens, pos_class=1):\r\n",
        "  y_real = np.array(test_gens[0].classes)\r\n",
        "  fig, ax1 = plt.subplots(1,1)\r\n",
        "  ax1.set_xlabel('False Positive Rate')\r\n",
        "  ax1.set_ylabel('True Positive Rate')\r\n",
        "  aspect = ['r--','g--','m--','c--','ro-','go-','c--','m--']\r\n",
        "  aucs = []\r\n",
        "  for i in range(len(models)):\r\n",
        "    model = models[i]\r\n",
        "    c = aspect[i]\r\n",
        "    y_pred_proba = model.predict(test_gens[i])\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_real==pos_class, y_pred_proba[:,pos_class])\r\n",
        "    au = auc(fpr, tpr)\r\n",
        "    ax1.plot(fpr, tpr, c , label = f'CNN {i+1} ({au:.2f})')\r\n",
        "    aucs.append(au)\r\n",
        "  ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\r\n",
        "  ax1.legend();\r\n",
        "  plt.show()\r\n",
        "  return aucs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "8F8gqiDLkhR6",
        "outputId": "e2cab2f3-cb76-4a70-9af7-5e24ec583ad3"
      },
      "source": [
        "aucs = get_roc([model,tot_model,tot_model_2],[test_generator,test_generator_tl,test_generator_tl_2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHNxrsCVD6on"
      },
      "source": [
        "Representando las curvas roc de cada uno de los modelos, se puede observar claramente que ninguno de ellos es util para obtener información de las imágenes de entrada. A continuación se ha probado a sustituir las capas densas por un Support Vector Classifier, sin obtener ningún resultado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUjY7nTeBWBg"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5fbNgpZwKpC"
      },
      "source": [
        "efficient_2.trainable=False\r\n",
        "global_avg = GlobalAveragePooling2D()(efficient_2.output)\r\n",
        "svm = Model(inputs = efficient_2.input, outputs = global_avg)\r\n",
        "svm.compile()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anivx0nkwwtw",
        "outputId": "72bff4d0-480a-4fde-ca28-21a59ccb5c52"
      },
      "source": [
        "target_size_2 = (600,600)\r\n",
        "batch_size = 1\r\n",
        "\r\n",
        "train_generator_tl_3 = train_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_train,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size_2,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "val_generator_tl_3 = val_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_val,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size_2,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "test_generator_tl_3 = test_gen.flow_from_dataframe(\r\n",
        "    dataframe=df_test,\r\n",
        "    x_col = \"filepath\",\r\n",
        "    y_col = \"class\",\r\n",
        "    target_size = target_size_2,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 935 validated image filenames belonging to 2 classes.\n",
            "Found 268 validated image filenames belonging to 2 classes.\n",
            "Found 133 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezbr5_iIt36T"
      },
      "source": [
        "features_train = svm.predict(train_generator_tl_3)\r\n",
        "features_val = svm.predict(val_generator_tl_3)\r\n",
        "features_test = svm.predict(test_generator_tl_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPyrfopfu1Ip"
      },
      "source": [
        "feat_train_df = pd.DataFrame(features_train)\r\n",
        "feat_train_df['labels'] = train_generator_tl_3.labels\r\n",
        "\r\n",
        "feat_val_df = pd.DataFrame(features_val)\r\n",
        "feat_val_df['labels'] = val_generator_tl_3.labels\r\n",
        "\r\n",
        "feat_test_df = pd.DataFrame(features_test)\r\n",
        "feat_test_df['labels'] = test_generator_tl_3.labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnx7dudZx0RI"
      },
      "source": [
        "X_train = feat_train_df.iloc[:,:-1]\r\n",
        "Y_train = feat_train_df.iloc[:,-1]\r\n",
        "\r\n",
        "X_val = feat_val_df.iloc[:,:-1]\r\n",
        "Y_val = feat_val_df.iloc[:,-1]\r\n",
        "\r\n",
        "X_test = feat_test_df.iloc[:,:-1]\r\n",
        "Y_test = feat_test_df.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyClN-X73QNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b577b8-063e-424a-8c44-0824d6d5ef66"
      },
      "source": [
        "model_ml = SVC(C=0.8)\r\n",
        "model_ml.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB8a_7ZO4ZHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476c916c-9b10-4487-a7bc-e78cb8572701"
      },
      "source": [
        "model_ml.score(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5336898395721925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRsjzChn4Zt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50066ba-c33d-4d83-abcc-01ea4a6b1adc"
      },
      "source": [
        "model_ml.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5338345864661654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yecuWAbkne8q"
      },
      "source": [
        "## Visualización de la red\r\n",
        "\r\n",
        "Finalmente, se ha diseñado un pequeño código para poder visualizar las salidas de cada capa de la red, observando que salen mayormente negras. Esto concuerda con el hecho de que no obtengan información."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0QdoHTwFKY1"
      },
      "source": [
        "batch=30\r\n",
        "n = 3\r\n",
        "ncapa = 1\r\n",
        "\r\n",
        "def print_layer_exits(model, layer_ind, generator, batch, n):\r\n",
        "  int_model = Model(inputs=model.input, outputs=model.layers[layer_ind].output)\r\n",
        "  image = generator[batch][0][n]\r\n",
        "  aux = np.expand_dims(image, axis=0)\r\n",
        "  result = int_model.predict(aux)\r\n",
        "\r\n",
        "  plt.figure(figsize=(3,3))\r\n",
        "  plt.imshow(image, cmap='gray')\r\n",
        "  plt.title('input image', size=12)\r\n",
        "  plt.xticks(())\r\n",
        "  plt.yticks(())\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  print(f\"Exits from layer {int_model.layers[-1].name} (Shape {result.shape})\")\r\n",
        "\r\n",
        "  n_exits = result.shape[-1]\r\n",
        "  ncols = 4\r\n",
        "  nrows = int(np.ceil(n_exits / ncols))\r\n",
        "\r\n",
        "  ma = abs(result).max()\r\n",
        "\r\n",
        "  plt.subplots(nrows,ncols,figsize = (12, 3*nrows))\r\n",
        "\r\n",
        "  for i in range(n_exits):\r\n",
        "      plt.subplot(nrows,ncols,i+1)\r\n",
        "      plt.imshow(result[0,:,:,i], vmin=-ma, vmax=ma, cmap='bwr')\r\n",
        "      plt.imshow(result[0,:,:,i], cmap='viridis')\r\n",
        "      plt.xticks(())\r\n",
        "      plt.yticks(())\r\n",
        "      plt.title('Exit from kernel %d' % i, fontsize=10)\r\n",
        "\r\n",
        "print_layer_exits(model, ncapa, train_generator, batch, n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-DQeocGGXgk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}